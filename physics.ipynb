{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.physics' from '/Users/aidanbx/CS/EINCASM/src/physics.py'>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import src.physics as physics\n",
    "importlib.reload(physics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation and Flow\n",
    "\n",
    "Each cell has a set of channel equal in length to the kernel (minus 1 for the origin cell) that denote the weight of connecting edges between that cell and the cell offset from the origin by the amounts specified in the kernel.\n",
    "\n",
    "The kernel is to be symmetric and start with the origin [0,0]. This means that by rolling the non-origin kernel by half of its length (length(kernel)-1) leaves the offsets in the order of their inverses. This mirrors a kernel. \n",
    "\n",
    "Each cell generates a single activation (though it is easy to allow for len(kernel) activations). This activation is positive or negative, as are the weights. If the result of multiplying the activation by the weights is negative, this indicates inverted flow (taking from a neighbor). To compute this, we can simply roll all negative flows such that they are in inverted positions and subtract (so add) them from the flows of their neighbors in the inverted direction (taking from your neighbor is the same as them giving something to you). \n",
    "\n",
    "At this point, the flow tensor should only include positive flows and previously negative flows should be set to 0. With this, we can evenly distribute the capital of each cell across its flows and update the capital of each cells' neighbors. This doesn't necessitate that all capital be moved from the cell, the activation could be small and flows associated with the origin (position 0) could be high, meaning capital is given to yourself in the next timestep.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000, 2.1600, 0.6400],\n",
       "        [1.2320, 0.3200, 0.8320],\n",
       "        [0.2560, 0.3200, 0.0000]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the kernel and world tensors\n",
    "# Each kernel element is a shift along the 0 and 1 axes of the world for each channel/layer\n",
    "kernel = torch.tensor([\n",
    "    [0, 0],     # ORIGIN\n",
    "    [-1, 0],     # UP\n",
    "    [0, 1.0],   # RIGHT\n",
    "    [1, 0],     # DOWN\n",
    "    [0, -1]    # LEFT\n",
    "])\n",
    "\n",
    "muscle_radii = torch.tensor([\n",
    "    [[-1,  1, 0],      # (0,0) ORIGIN\n",
    "     [-0.8,  0.8, 0],  \n",
    "     [0, 0, 0]],  \n",
    "\n",
    "    [[-0.6, 0.6, 0],    # UP\n",
    "     [-0.4, 0.4, 0],   \n",
    "     [0, 0, 0]],   \n",
    "\n",
    "    [[-0.2, 0.2, 0],    # RIGHT\n",
    "     [0, 0, 0],\n",
    "     [0, 0, 0]],\n",
    "    \n",
    "    [[0.2, -0.2, 0],    # DOWN\n",
    "     [0.4, -0.4, 0],\n",
    "     [0, 0, 0]],\n",
    "    \n",
    "    [[0.6, -0.6, 0],    # LEFT\n",
    "     [0.8, -0.8, 0],\n",
    "     [0, 0, 0]]\n",
    "])\n",
    "\n",
    "activations = torch.tensor([\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 0],\n",
    "    [0, 0, 0]\n",
    "])\n",
    "\n",
    "capital = torch.tensor([\n",
    "    [4, 3.0, 0],\n",
    "    [2, 1, 0],\n",
    "    [0, 0, 0]\n",
    "])\n",
    "before = capital.clone()\n",
    "\n",
    "flow_efficiency = torch.tensor([\n",
    "    [0.8, 0.8, 0.8],\n",
    "    [0.8, 0.8, 0.8],\n",
    "    [0.8, 0.8, 0.8]\n",
    "])\n",
    "\n",
    "physics.activate_muscles_and_flow(capital, muscle_radii, activations, flow_efficiency, kernel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muscle Growth\n",
    "\n",
    "Cell growth in EINCASM requires an exchange of a cell's capital to slowly adjust the magnitude of a muscle oriented in a specific direction. If the change in magnitude of a muscle is positive, capital is taken from the cell with an adjustment for \"heat loss\" reflecting the efficiency of the process. If the change in magnitude is negative, capital, minus a loss, is returned to the cell. \n",
    "\n",
    "Muscles, as explained in #Activation and Flow, have an orientation and can be positive or negative. They are encoded in the world tensor as a set of channels where each is associated via order of index with the kernel, which contains offsets. If EINCASM is set up to only have a singular positive or negative activation per cell, then negative and positive muscles always have inverted flows in respect to each other. Because a cell can only change its muscle weights slowly and at a cost of wasted capital, it is to their advantage to choose an orientation and stick to it. \n",
    "\n",
    "There a multiple ways muscle growth can be accounted for in EINCASM. The default set up is to have the muscle channels denote the radius and charge of a muscle fiber. The output of the physiology of each cell indicates a change in radius, but the cost of growth is proportional to the cross-sectional area of the new muscle radius minus the original. This set up is chosen to enable flexibilty at a wider range of muscle magnitude scales without drastic changes to weights within the physiology (a neural network). The same cell that controls the small, exploratory muscle fibers/transport tubes can control the very large, established muscles next to large nutrient sources. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obstacles and Obstacle Masks\n",
    "\n",
    "Obstacles are currently handled during muscle growth rather than flow. No muscle can grow in the direction of an adjacent obstacle. It is possible to implement this during flow where capital rebounds to the origin cell, but handling this during muscle growth is simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.tensor([\n",
    "    [0, 0],     # ORIGIN\n",
    "    [-1, 0],    # UP\n",
    "    [0, 1.0],   # RIGHT\n",
    "    [1, 0],     # DOWN\n",
    "    [0, -1]     # LEFT\n",
    "])\n",
    "\n",
    "muscle_radii = torch.tensor([\n",
    "    [[0,  0],   # ORIGIN\n",
    "     [0,  0]],  \n",
    "\n",
    "   [[-1, -4.0], # UP\n",
    "    [1, 4]],   \n",
    "\n",
    "   [[2, 1],     # RIGHT\n",
    "    [2, 5]],\n",
    "    \n",
    "   [[0.0, 0.0], # DOWN\n",
    "    [0.0, 0.0]],\n",
    "    \n",
    "   [[0.0, 0.0], # LEFT\n",
    "    [0.0, 0.0]]\n",
    "])\n",
    "\n",
    "radii_deltas = torch.tensor([\n",
    "    [[0, 0],        # ORIGIN\n",
    "     [0, 0]],\n",
    "\n",
    "    [[1.0, 2.0],    # UP\n",
    "     [-3.0, 1.0]],\n",
    "\n",
    "    [[1.0, -1.0],   # RIGHT\n",
    "     [-4.0, 2.0]],\n",
    "\n",
    "    [[0.0, 0.0],    # DOWN\n",
    "     [0.0, 0.0]],\n",
    "\n",
    "    [[0.0, 0.0],    # LEFT\n",
    "     [0.0, 0.0]]\n",
    "])     \n",
    "\n",
    "capital = torch.tensor([\n",
    "    [5.0, 3.0],\n",
    "    [4.0, 0.0]\n",
    "])\n",
    "\n",
    "growth_efficiency = torch.tensor([\n",
    "    [0.8, 0.85],\n",
    "    [0.9, 1.0]\n",
    "])\n",
    "\n",
    "open_cells = torch.tensor([\n",
    "    [1, 1],\n",
    "    [1, 0],\n",
    "], dtype=torch.bool) # 1 = free, 0 = obstacle\n",
    "\n",
    "directional_masks = torch.ones_like(muscle_radii, dtype=torch.bool)\n",
    "\n",
    "for i in range(kernel.shape[0]):\n",
    "    directional_masks[i] = torch.roll(open_cells, shifts=tuple(map(int, -kernel[i])), dims=[0, 1])\n",
    "\n",
    "muscle_masks = directional_masks&open_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.2891,  0.0000],\n",
       "          [-2.1448,  0.0000]],\n",
       " \n",
       "         [[ 2.9251, -0.9220],\n",
       "          [ 0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000]]]),\n",
       " tensor([[0.0000, 2.8500],\n",
       "         [0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics.grow_muscle_csa(muscle_radii, radii_deltas, capital, growth_efficiency, muscle_masks, open_cells)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
